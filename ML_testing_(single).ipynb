{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "test_features = pd.read_csv('kaggle_data/test_features.csv')\n",
    "train_features = pd.read_csv('kaggle_data/train_features.csv')\n",
    "tt_nonscored = pd.read_csv('kaggle_data/train_targets_nonscored.csv')\n",
    "tt_scored = pd.read_csv('kaggle_data/train_targets_scored.csv')\n",
    "ss = pd.read_csv('kaggle_data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=22)\n",
    "\n",
    "ovr_class = OneVsRestClassifier(SGDClassifier(loss='log', max_iter=25000, n_jobs=-1, random_state=34, \n",
    "                                              learning_rate='constant', eta0=0.002, alpha=0.004, shuffle=True), n_jobs=-1)\n",
    "clf = Pipeline([('ss', StandardScaler()),  ('classifier', ovr_class)])\n",
    "\n",
    "ovr_class_2 = OneVsRestClassifier(LogisticRegression(random_state=34, n_jobs=-1, multi_class='multinomial'),n_jobs=-1)\n",
    "clf2 = Pipeline([('ss', StandardScaler()), ('classifier', ovr_class_2)])\n",
    "\n",
    "params = {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1, 'booster': 'gbtree',\n",
    "         'tree_method': 'hist', 'n_jobs':-1,\n",
    "          'random_state':34} \n",
    "\n",
    "xgb_cl = OneVsRestClassifier(XGBClassifier(**params),n_jobs=-1)\n",
    "clf3 = Pipeline([('ss', StandardScaler()), ('classifier', xgb_cl)])\n",
    "\n",
    "rf_cl = OneVsRestClassifier(RandomForestClassifier(n_estimators=200, max_depth = 10, n_jobs=-1, random_state=34), n_jobs=-1)\n",
    "clf4 = Pipeline([('ss', StandardScaler()), ('classifier', rf_cl)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(pd.concat([tr_gene_df, tr_cell_df]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'sig_id' column \n",
    "\n",
    "full_dfs = [tt_scored]\n",
    "def col_drop(df):\n",
    "    df = df.drop(columns=['sig_id'], axis=1, inplace=True)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "for df in full_dfs:\n",
    "    col_drop(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of DataFrames\n",
    "\n",
    "dfs = [train_features, test_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send DataFrames through mapping function\n",
    "\n",
    "def cleaner(df):\n",
    "    df['cp_type'] = df['cp_type'].map({'ctl_vehicle': 0, 'trt_cp': 1})\n",
    "    df['cp_time'] = df['cp_time'].map({24: 1, 48: 2, 72: 3})\n",
    "    df['cp_dose'] = df['cp_dose'].map({'D1': 0 , 'D2': 1})\n",
    "    return df\n",
    "\n",
    "\n",
    "for df in dfs:\n",
    "    cleaner(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23814, 876), (3982, 876))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of DataFrames\n",
    "\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find indicies that do not have '0' under the 'cp_type' feature, match and slice the dataframes\n",
    "## Kept this code commented out because doing so made the models perform worse\n",
    "\n",
    "#keep_idx_test = test_features[test_features.cp_type != 0].index\n",
    "#keep_idx_train = train_features[train_features.cp_type != 0].index\n",
    "\n",
    "#test_features = test_features.loc[keep_idx_test]\n",
    "#train_features = train_features.loc[keep_idx_train]\n",
    "#tt_scored = tt_scored.loc[keep_idx_train]\n",
    "#train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23814, 875), (23814, 206), (3982, 875))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create feature-unique lists and dataframes for further examination and to limit dimentiality when training model\n",
    "\n",
    "g_cols = [col for col in train_features if 'g-' in col]\n",
    "c_cols = [col for col in train_features if 'c-' in col]\n",
    "\n",
    "tr_gene_df = train_features.loc[:, 'g-0':'g-771']\n",
    "tr_cell_df = train_features.loc[:, 'c-0':]\n",
    "\n",
    "tr_cols = train_features.loc[:, 'cp_type':]\n",
    "tr_cols.shape, tt_scored.shape\n",
    "\n",
    "test_cols = test_features.loc[:, 'cp_type':]\n",
    "tr_cols.shape, tt_scored.shape, test_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23814, 833), (3982, 833))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found through EDA notebook, remove these extreme outlier features to reduce dimentiality\n",
    "\n",
    "dfs = [tr_cols,test_cols]\n",
    "col_list = ['g-496', 'g-333', 'g-676', 'g-127', 'g-39', 'g-360', 'g-28', 'g-19', 'g-184', 'g-110', 'g-687', 'g-216',\n",
    "            'g-15', 'g-626', 'g-393', 'g-667', 'g-164', 'g-688', 'g-754', 'g-557', 'g-363', 'g-132', 'g-435', 'g-536',\n",
    "            'g-550', 'g-481','g-611', 'g-18', 'g-756', 'g-331', 'g-618', 'g-718', 'g-370', 'g-219','g-153','g-46','g-238',\n",
    "            'g-23','g-707','g-213','g-307','g-104']\n",
    "\n",
    " \n",
    "def outlier_drop(df, col):\n",
    "    df = df.drop([col], axis=1, inplace=True)\n",
    "    return df\n",
    "for col in col_list:\n",
    "    for df in dfs:\n",
    "        outlier_drop(df, col)\n",
    "tr_cols.shape, test_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframes to matricies for model input\n",
    "\n",
    "X, y, test = np.array(tr_cols), np.array(tt_scored), np.array(test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe and lists for metric/evaluation outputs\n",
    "\n",
    "oof_preds = np.zeros(y.shape)\n",
    "oof_losses = []\n",
    "list_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold time:  11.34304928779602\n",
      "fold time:  11.634966850280762\n",
      "fold time:  11.603526830673218\n",
      "fold time:  11.533483266830444\n",
      "fold time:  11.438003778457642\n",
      "[0.01670911375545155, 0.016992782722502972, 0.01724335821926487, 0.016240868223501997, 0.016883533478118513]\n"
     ]
    }
   ],
   "source": [
    "# first model\n",
    "\n",
    "for k_f, (tr_idx, t_idx) in enumerate(kf.split(X, y)):\n",
    "    fold_start = time.time()\n",
    "    \n",
    "    X_train, X_val = X[tr_idx], X[t_idx]\n",
    "    y_train, y_val = y[tr_idx], y[t_idx]\n",
    "    \n",
    "    clf1 = clf.fit(X_train, y_train)\n",
    "    val_preds = clf.predict_proba(X_val)\n",
    "    val_preds = np.array(val_preds)\n",
    "    oof_preds[t_idx] = np.array(val_preds)\n",
    "    loss = log_loss(np.ravel(y_val), np.ravel(val_preds))\n",
    "    oof_losses.append(loss)\n",
    "    \n",
    "    preds = clf.predict_proba(test)\n",
    "    list_preds.append(preds)\n",
    "    \n",
    "    \n",
    "    fold_end = time.time()\n",
    "    print('fold time: ', fold_end - fold_start)\n",
    "        \n",
    "print(oof_losses)\n",
    "# print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold time:  583.1211156845093\n",
      "fold time:  580.9785079956055\n",
      "fold time:  576.304976940155\n",
      "fold time:  581.6895434856415\n",
      "fold time:  576.6104669570923\n",
      "[0.030242662109904228, 0.031145176664757922, 0.031212612469562716, 0.02901750874922711, 0.031257828227517416]\n"
     ]
    }
   ],
   "source": [
    "# second model \n",
    "\n",
    "oof_preds2 = np.zeros(y.shape)\n",
    "oof_losses2 = []\n",
    "\n",
    "for k_f, (tr_idx, t_idx) in enumerate(kf.split(X, y)):\n",
    "    fold_start = time.time()\n",
    "    \n",
    "    X_train, X_val = X[tr_idx], X[t_idx]\n",
    "    y_train, y_val = y[tr_idx], y[t_idx]\n",
    "    \n",
    "    clf2 = clf2.fit(X_train, y_train)\n",
    "    val_preds2 = clf2.predict_proba(X_val)\n",
    "    val_preds2 = np.array(val_preds2)\n",
    "    oof_preds2[t_idx] = np.array(val_preds2)\n",
    "    \n",
    "    loss2 = log_loss(np.ravel(y_val), np.ravel(val_preds2))\n",
    "    oof_losses2.append(loss2)\n",
    "    \n",
    "    # preds2 = clf2.predict_proba(test)\n",
    "    \n",
    "    \n",
    "    fold_end = time.time()\n",
    "    print('fold time: ', fold_end - fold_start)\n",
    "        \n",
    "print(oof_losses2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold time:  744.5497477054596\n",
      "fold time:  753.6238639354706\n",
      "fold time:  770.0116214752197\n",
      "fold time:  802.581018447876\n",
      "fold time:  746.485387802124\n",
      "[0.021129359037136582, 0.021639216346358108, 0.021779772649308103, 0.020202002061217948, 0.02137149255399953]\n"
     ]
    }
   ],
   "source": [
    "# third model\n",
    "\n",
    "oof_preds3 = np.zeros(y.shape)\n",
    "oof_losses3 = []\n",
    "\n",
    "for k_f, (tr_idx, t_idx) in enumerate(kf.split(X, y)):\n",
    "    fold_start = time.time()\n",
    "    \n",
    "    X_train, X_val = X[tr_idx], X[t_idx]\n",
    "    y_train, y_val = y[tr_idx], y[t_idx]\n",
    "    \n",
    "    clf3 = clf3.fit(X_train, y_train) \n",
    "    val_preds3 = clf3.predict_proba(X_val)\n",
    "    val_preds3 = np.array(val_preds3)\n",
    "    oof_preds3[t_idx] = np.array(val_preds3)\n",
    "    \n",
    "    loss3 = log_loss(np.ravel(y_val), np.ravel(val_preds3))\n",
    "    oof_losses3.append(loss3)\n",
    "    \n",
    "    fold_end = time.time()\n",
    "    print('fold time: ', fold_end - fold_start)\n",
    "print(oof_losses3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold time:  575.3615190982819\n",
      "fold time:  576.5796873569489\n",
      "fold time:  572.8690297603607\n",
      "fold time:  580.7065134048462\n",
      "fold time:  575.86767578125\n",
      "[0.01991970239313964, 0.020351519318704846, 0.02093639339655242, 0.019168043720590784, 0.020690117126422273]\n"
     ]
    }
   ],
   "source": [
    "# fourth model \n",
    "\n",
    "oof_preds4 = np.zeros(y.shape)\n",
    "oof_losses4 = []\n",
    "\n",
    "for k_f, (tr_idx, t_idx) in enumerate(kf.split(X, y)):\n",
    "    fold_start = time.time()\n",
    "    \n",
    "    X_train, X_val = X[tr_idx], X[t_idx]\n",
    "    y_train, y_val = y[tr_idx], y[t_idx]\n",
    "    \n",
    "    clf4 = clf4.fit(X_train, y_train) \n",
    "    val_preds4 = clf4.predict_proba(X_val)\n",
    "    val_preds4 = np.array(val_preds4)\n",
    "    oof_preds4[t_idx] = np.array(val_preds4)\n",
    "    loss4 = log_loss(np.ravel(y_val), np.ravel(val_preds4))\n",
    "    oof_losses4.append(loss4)\n",
    "    \n",
    "    fold_end = time.time()\n",
    "    print('fold time: ', fold_end - fold_start)\n",
    "print(oof_losses4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.92, 0.92, 10.13, 12.41]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creat list and append output of 'time' for-loop to record prediction times for each model\n",
    "\n",
    "models = ['SGDClassifier', 'Linear Regression', 'XGBoostClassifier', 'RandomForestClassifier']\n",
    "clfs = [clf1, clf2, clf3, clf4]\n",
    "model_predict_time = []\n",
    "\n",
    "for clf in clfs:\n",
    "    pred_start = time.time()\n",
    "    clf.predict(test)\n",
    "    pred_finish = time.time()\n",
    "    total = round((pred_finish - pred_start),2)\n",
    "    model_predict_time.append(total)\n",
    "    \n",
    "model_predict_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([11.690075635910034, 578.7450776100159, 763.45032787323, 576.2768850803375],\n",
       " [0.016813928357025127,\n",
       "  0.030575128977418726,\n",
       "  0.02122436234413888,\n",
       "  0.020213135162446088])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list and append the mean train & predict time during each KFold trip\n",
    "# create list and append the mean log loss score across all 5 KFolds\n",
    "\n",
    "vals = [oof_preds, oof_preds2, oof_preds3, oof_preds4]\n",
    "model_times = [SGD_time, LR_time, XGB_time, RF_time]\n",
    "\n",
    "mean_ll = []\n",
    "mean_tp_time = []\n",
    "\n",
    "for val, time in zip(vals, model_times):\n",
    "    m_loss = log_loss(np.ravel(y), np.ravel(val))\n",
    "    m_time = np.mean(time)\n",
    "    mean_ll.append(m_loss)\n",
    "    mean_tp_time.append(m_time)\n",
    "mean_tp_time, mean_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of each KFold log loss output and train & predict times, respectively\n",
    "\n",
    "\n",
    "SGD_lls = [0.01670911375545155, 0.016992782722502972, 0.01724335821926487, 0.016240868223501997, 0.016883533478118513] \n",
    "LR_lls = [0.030242662109904228, 0.031145176664757922, 0.031212612469562716, 0.02901750874922711, 0.031257828227517416]\n",
    "XGB_lls = [0.021129359037136582, 0.021639216346358108, 0.021779772649308103, 0.020202002061217948, 0.02137149255399953]\n",
    "RF_lls = [0.01991970239313964, 0.020351519318704846, 0.02093639339655242, 0.019168043720590784, 0.020690117126422273]\n",
    "\n",
    "\n",
    "SGD_time = [12.514066696166992, 11.79899001121521, 11.581927299499512, 11.190450191497803, 11.364943981170654]\n",
    "LR_time = [582.286411523819, 580.2102625370026, 575.5257470607758, 580.1989614963531, 575.5040054321289]\n",
    "XGB_time = [744.5497477054596, 753.6238639354706, 770.0116214752197, 802.581018447876, 746.485387802124]\n",
    "RF_time = [575.3615190982819, 576.5796873569489, 572.8690297603607, 580.7065134048462, 575.86767578125]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>OVR_wrap</th>\n",
       "      <th>StandardScaler</th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>mean_log_loss: 5-fold</th>\n",
       "      <th>mean_train_&amp;_predict_time: (sec)</th>\n",
       "      <th>model_predict_time</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.016814</td>\n",
       "      <td>11.690076</td>\n",
       "      <td>0.92</td>\n",
       "      <td>all original, minus 42 \"gene expression\" columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.030575</td>\n",
       "      <td>578.745078</td>\n",
       "      <td>0.92</td>\n",
       "      <td>all original, minus 42 \"gene expression\" columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.021224</td>\n",
       "      <td>763.450328</td>\n",
       "      <td>10.13</td>\n",
       "      <td>all original, minus 42 \"gene expression\" columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.020213</td>\n",
       "      <td>576.276885</td>\n",
       "      <td>12.41</td>\n",
       "      <td>all original, minus 42 \"gene expression\" columns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  OVR_wrap  StandardScaler  Pipeline  \\\n",
       "0           SGDClassifier      True            True      True   \n",
       "1       Linear Regression      True            True      True   \n",
       "2       XGBoostClassifier      True            True      True   \n",
       "3  RandomForestClassifier      True            True      True   \n",
       "\n",
       "   mean_log_loss: 5-fold  mean_train_&_predict_time: (sec)  \\\n",
       "0               0.016814                         11.690076   \n",
       "1               0.030575                        578.745078   \n",
       "2               0.021224                        763.450328   \n",
       "3               0.020213                        576.276885   \n",
       "\n",
       "   model_predict_time                                          features  \n",
       "0                0.92  all original, minus 42 \"gene expression\" columns  \n",
       "1                0.92  all original, minus 42 \"gene expression\" columns  \n",
       "2               10.13  all original, minus 42 \"gene expression\" columns  \n",
       "3               12.41  all original, minus 42 \"gene expression\" columns  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create datatframe of final evaluation metrics and descriptions and export as csv file\n",
    "\n",
    "metrics = {'model': models, 'OVR_wrap': True, 'StandardScaler': True, 'Pipeline': True, 'mean_log_loss: 5-fold':mean_ll, \n",
    "           'mean_train_&_predict_time: (sec)': mean_tp_time, 'model_predict_time':model_predict_time, \n",
    "           'features': 'all original, minus 42 \"gene expression\" columns'}\n",
    "\n",
    "df = pd.DataFrame(metrics)\n",
    "df.to_csv('Model_metrics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pickle to save model\n",
    "\n",
    "pickle.dump(clf1, open('OvR', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
